{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "979b6f8823bbd681f0a04e070b770d1a",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Homewok 1 ML\n",
    "## Warning: \n",
    "### Don't even try to add new Import or you will marked 0 point\n",
    "### Don't make an infinite loop or you or you will marked 0 point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put your npm as string below\n",
    "NPM = \"\"\n",
    "\n",
    "#if someone that also take an ML class this year help you doing this assingment,put his/her NPM as list of string below\n",
    "COLLABORATORS = []\n",
    "\n",
    "#if youre using external sources please put its link as list of string below\n",
    "SOURCES = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4668bf8743c05b811c5d03a5fc6115d8",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "21a67f669f8cc8a0d97ceb97556ba2f4",
     "grade": false,
     "grade_id": "helper_func",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def is_similar(X, Y):\n",
    "    if isinstance(X, list) and isinstance(Y, list):\n",
    "        if len(X) == len(Y):\n",
    "            return all([is_similar(x,Y[i]) for i,x in enumerate(X)])\n",
    "        else:\n",
    "            return False\n",
    "    return abs(X-Y) <= 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "40c65eee2c40c843125e2074cfbf409d",
     "grade": true,
     "grade_id": "import_check_helper",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6e452e5999e2d507915805f16265a98d",
     "grade": false,
     "grade_id": "header_linreg",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f99b99903004b5eb5eb2a883dcbdc551",
     "grade": false,
     "grade_id": "hx_quest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### score: 1 point\n",
    "without using any external library, implement h(x)\n",
    "\n",
    "$$ h(x) = \\theta^Tx $$\n",
    "\n",
    "with thetas as $\\theta$ (represented as list)\n",
    "\n",
    "x represented as list with the same length with thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8bc4be778d7df98094b52982e87ab79c",
     "grade": false,
     "grade_id": "hx_ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def hx(x):\n",
    "    global theta\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "49cdd85e487934efc9ce8090c6cae440",
     "grade": true,
     "grade_id": "hx_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "theta, x = [1,2,3], [2,3,4]\n",
    "assert is_similar(hx(x),20)\n",
    "\n",
    "theta, x = [-1,-1,-1], [2,3,4]\n",
    "assert is_similar(hx(x),-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "809a9f446d3003ff64281be4c3892844",
     "grade": false,
     "grade_id": "JOfTheta_quest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### score: 1 point\n",
    "\n",
    "without using any external library, using hx implemented above, implement $J(\\theta)$\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2}\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2 $$\n",
    "\n",
    "y as list of target value\n",
    "\n",
    "with X as list of list of example coresponding to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c3d49190a179b55da2b38f719cbf1484",
     "grade": false,
     "grade_id": "JOfTheta_ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def cost_func(X, y):\n",
    "    m = len(y)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "98d43d25d33f536e2896eff7c9d6857f",
     "grade": true,
     "grade_id": "JOfTheta_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "theta, X, y = [-1, 0], [[1,1],[0,1]], [-1,0]\n",
    "assert is_similar(cost_func(X,y),0)\n",
    "\n",
    "theta, X, y = [1, 1, 2], [[1,1,1],[0,0,0]], [0,0]\n",
    "assert is_similar(cost_func(X,y),8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b2eb755912c468c627e02840277bf59d",
     "grade": false,
     "grade_id": "sgd_quest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### score: 1 point\n",
    "without using any external library, implement one iteration of stochastic gradient descent that use cost function above as error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dd2e4433daf1b56ea5a78e86e5cc11ae",
     "grade": false,
     "grade_id": "sgd_ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def one_iteration_of_SGD(X, y, lr=1e-4):\n",
    "    global theta\n",
    "    alpha, m = lr, len(y)\n",
    "    for i in range(m):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d462257663781eedb12724d22c1ec8d1",
     "grade": true,
     "grade_id": "sgd_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "theta, X, y = [1, 2, 1], [],[]\n",
    "# optimal theta is [0,1,-1]\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        X.append([1,i,j])\n",
    "        y.append(i-j)\n",
    "theta = one_iteration_of_SGD(X, y, lr=0.02)\n",
    "assert is_similar(theta,[0.026437395230493967, 1.0273911806101215, -0.9817775908722853])\n",
    "theta = one_iteration_of_SGD(X, y, lr=0.02)\n",
    "assert is_similar(theta,[0.008423488895377855, 0.9997426554553306, -0.9996855620207235])\n",
    "theta = one_iteration_of_SGD(X, y, lr=0.02)\n",
    "assert is_similar(theta,[0.0070527414486398375, 0.9990690600988367, -1.0001740371160284])\n",
    "theta = one_iteration_of_SGD(X, y, lr=0.02)\n",
    "assert is_similar(theta,[0.006252955113893083, 0.999152947934675, -1.0001675531854075])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAYGROUND\n",
    "# you can do anything here as long as not adding any new import\n",
    "\n",
    "theta, X, y = [1, 2, 1], [],[]\n",
    "# optimal theta is [0,1,-1]\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        X.append([1,i,j])\n",
    "        y.append(i-j)\n",
    "\n",
    "history = []\n",
    "print('cost func before', cost_func(X,y))\n",
    "print('theta(weight) before', theta)\n",
    "for i in range(20):\n",
    "    history.append(cost_func(X,y)) \n",
    "    theta = one_iteration_of_SGD(X, y, lr=0.02)\n",
    "print('cost func after 20 iteration', cost_func(X,y))\n",
    "print('theta(weight) after 20 iteration', theta)\n",
    "\n",
    "print('\\ncost/loss func plot')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history)\n",
    "plt.xlabel('number of iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print('\\033[1mcongratulations you have implemented linear regression from scratch \\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7d083efe63ab16adf9b1269c42140fa5",
     "grade": false,
     "grade_id": "header_glm",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# GLM (Softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cd4b53ec4de05217534f21f8de9f104a",
     "grade": false,
     "grade_id": "softmax_quest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### score: 1 point\n",
    "without using any external library, implement a softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0f9df8ea2547434d4937effd690ffd02",
     "grade": false,
     "grade_id": "softmax_ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    e = 2.718281828459045\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "37e5e77d76a2c04e0e78a0cde1454ffb",
     "grade": true,
     "grade_id": "softmax_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert is_similar(softmax([1]), [1])\n",
    "assert is_similar(softmax([100]), [1])\n",
    "assert is_similar(softmax([0.123]), [1])\n",
    "assert is_similar(softmax([1, 1]), [0.5, 0.5])\n",
    "assert is_similar(softmax([123, 123, 123, 123]), [0.25, 0.25, 0.25, 0.25])\n",
    "assert is_similar(softmax([10, 1]), [0.9998766054240137, 0.0001233945759862318])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "668a8f05585e62c7535eb7540a3d8f01",
     "grade": false,
     "grade_id": "softmax_reg_quest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### score: 1 point\n",
    "without using any external library, given theta/weight of a layer and x as features vector implement a single input softmax regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e0225694db12b7cfccd4ff448d332d86",
     "grade": false,
     "grade_id": "softmax_reg_ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def single_softmax_regression(x):\n",
    "    global thetas\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def softmax_regression(X):\n",
    "    return [single_softmax_regression(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0e3d483d60b13cb44c3a215273059714",
     "grade": true,
     "grade_id": "softmax_reg_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "thetas = [[0,0],[0,0]]\n",
    "assert is_similar(softmax_regression([[1,0],[0,1]]),[[0.5, 0.5], [0.5, 0.5]])\n",
    "thetas = [[1,0], [0,1]]\n",
    "assert is_similar(softmax_regression([[1,0],[0,1]]),[[0.7310585786300049, 0.2689414213699951], [0.2689414213699951, 0.7310585786300049]])\n",
    "thetas = [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "assert is_similar(softmax_regression([[1, 1, 1, 2], [1,2, 1, 3]]),[[0.25, 0.25, 0.25, 0.25], [0.25, 0.25, 0.25, 0.25]])\n",
    "thetas = [[0, 0, 0, 100], [1, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "assert is_similar(softmax_regression([[1, 1, 1, 1], [0,0, 1, 0], [100,0,0,1]]),[[1, 0, 0, 0], [0.25, 0.25, 0.25, 0.25], [0.5, 0.5, 0, 0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f18d0a2302f85b97237eb12de3afa62f",
     "grade": false,
     "grade_id": "softmax_predict_quest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### score: 1 point\n",
    "without using any external library, given X as matrics of features(column) and datapoint(row) output its one hot encoded predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5e560d52d016ff93d829b69c85ee3ec8",
     "grade": false,
     "grade_id": "softmax_predict_ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_class(X):\n",
    "    likelyhoods = softmax_regression(X)\n",
    "    classes = [[0 for i in range(len(x))] for x in X]\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "70a0c1c62116cbd649f59c2f79a6c26e",
     "grade": true,
     "grade_id": "softmax_predict_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "thetas = [[1,0], [0,1]]\n",
    "assert predict_class([[1,0],[0,1]]) == [[1, 0], [0, 1]]\n",
    "thetas = [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "\n",
    "thetas = [[0, 0, 0, 100], [1, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "assert predict_class([[1, 1, 1, 1]]) == [[1, 0, 0, 0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4f10dc985702ac86eef82d986168cbe1",
     "grade": true,
     "grade_id": "import_check_1",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d36c1670517f68a39153710d68aa4d0a",
     "grade": false,
     "grade_id": "header_gda",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Gaussian Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7bec1b281bea281fc2e24b55ad1c4e6c",
     "grade": true,
     "grade_id": "import_checker_helper_1",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e550b7767b70d29a732be7eb461bb784",
     "grade": false,
     "grade_id": "gda_quest",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### total score: 2 point\n",
    "##### 1 point for fit (correct sigma, mu0, mu1,  phi)\n",
    "##### 1 point for predict (correct compute_predict_proba_x_given_y,  compute_proba_y, predict_single)\n",
    "\n",
    "implement Gaussian Discriminant Analysis model for binary classification problem **you are only allowed to use numpy and numpy.linalg**\n",
    "\n",
    "use function fit to train the model\n",
    "\n",
    "and function predict to predict the trained model\n",
    "\n",
    "X is matrix of data (column as features, row as datapoint)\n",
    "\n",
    "y is vector of label (0 or 1) coresponding to X\n",
    "\n",
    "phi is $\\phi$\n",
    "\n",
    "mu0 is $\\mu0$\n",
    "\n",
    "mu1 is $\\mu1$\n",
    "\n",
    "sigma/covmat is $\\Sigma$\n",
    "\n",
    "### IMPLEMENTATION DETAIL\n",
    "**USE 1/(m-1) instead of 1/m for sigma/covmat or you can just use np.cov**\n",
    "\n",
    "**USE np.linalg.pinv instead of np.linalg.inv for inverse matrix (pseudo inverse instead of inverse)**\n",
    "\n",
    "**USE np.pi for pi**\n",
    "\n",
    "**USE np.det to get determinant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "74781002ae680f61d875a27dabeda76a",
     "grade": false,
     "grade_id": "gda_ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class GDA:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.phi = None\n",
    "        self.sigma = None\n",
    "        self.mu0 = None\n",
    "        self.mu1 = None\n",
    "    \n",
    "    # update phi, sigma, mu0(mean 0), mu1(mean 1) here\n",
    "    def fit(self, X, y):\n",
    "        m = y.shape[0]\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        self.mus = [self.mu0, self.mu1]\n",
    "\n",
    "    \n",
    "    # return p(y)\n",
    "    def compute_proba_y(self, y):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    # return p(x|y)\n",
    "    def compute_proba_x_given_y(self,x, y):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict_single(self, x):\n",
    "        proba_y0 = self.compute_proba_y(y=0)\n",
    "        proba_y1 = self.compute_proba_y(y=1)\n",
    "        \n",
    "        proba_x_given_y_0 = self.compute_proba_x_given_y(x, y=0)\n",
    "        proba_x_given_y_1 = self.compute_proba_x_given_y(x, y=1)\n",
    "        return 1 if proba_y1*proba_x_given_y_1 > proba_y0*proba_x_given_y_0 else 0\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return [self.predict_single(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6543a820a015a31df675ef47ff52535f",
     "grade": true,
     "grade_id": "gda_test_fit",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def test_gda_public():\n",
    "    X = np.zeros((1000,3))\n",
    "    np.random.seed(103)\n",
    "    X[0:500,0] = np.random.uniform(-3,1,500)\n",
    "    np.random.seed(47)\n",
    "    X[0:500,1] = np.random.uniform(-3,1,500)\n",
    "    np.random.seed(2019)\n",
    "    X[0:500,2] = np.random.uniform(-3,1,500)\n",
    "\n",
    "    np.random.seed(103)\n",
    "    X[500:,0] = np.random.uniform(-1,3,500)\n",
    "    np.random.seed(47)\n",
    "    X[500:,1] = np.random.uniform(-1,3,500)\n",
    "    np.random.seed(2019)\n",
    "    X[500:,2] = np.random.uniform(-3,1,500)\n",
    "    y = np.array([0 if i < 500 else 1 for i in range(1000)])\n",
    "\n",
    "    gda = GDA()\n",
    "    gda.fit(X,y)\n",
    "    return X, y, gda\n",
    "\n",
    "X,y, gda = test_gda_public()\n",
    "np.testing.assert_almost_equal(gda.phi, 0.5)\n",
    "np.testing.assert_array_almost_equal(gda.mu0, [-1.0170375245138221, -0.8837860293254437, -0.9928110497167374])\n",
    "np.testing.assert_array_almost_equal(gda.mu1, [0.982962475486178, 1.1162139706745566, -0.9928110497167374])\n",
    "np.testing.assert_array_almost_equal(gda.sigma, np.array([[ 1.31469689, -0.06407885, -0.03699664], [-0.06407885,  1.36877185, -0.04577584], [-0.03699664, -0.04577584,  1.3349875 ]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "393f2cf39cbe441f3e191fb48293b119",
     "grade": true,
     "grade_id": "gda_test_proba",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X,y, gda = test_gda_public()\n",
    "\n",
    "np.testing.assert_almost_equal(gda.compute_proba_y(1), 0.5)\n",
    "np.testing.assert_almost_equal(gda.compute_proba_y(0), 0.5)\n",
    "\n",
    "np.testing.assert_almost_equal(gda.compute_proba_x_given_y([-3, -3, -3], 1), 0)\n",
    "np.testing.assert_almost_equal(gda.compute_proba_x_given_y([-3, -3, -3], 0), 0.0002746507453048722)\n",
    "np.testing.assert_array_almost_equal(gda.predict([[-3,-3,-3]]), [0])\n",
    "\n",
    "np.testing.assert_almost_equal(gda.compute_proba_x_given_y([3, 3, 1], 1), 0.0003846724892885247)\n",
    "np.testing.assert_almost_equal(gda.compute_proba_x_given_y([3, 3, 1], 0), 0)\n",
    "np.testing.assert_array_almost_equal(gda.predict([[3, 3, 1]]), [1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAYGROUND\n",
    "# you can do anything here as long as not adding any new import or breaking stuff\n",
    "\n",
    "X = np.zeros((1000,2))\n",
    "\n",
    "# for targe label 0\n",
    "np.random.seed(103)\n",
    "X[0:500,0] = np.random.uniform(-3,1,500)\n",
    "np.random.seed(47)\n",
    "X[0:500,1] = np.random.uniform(-3,1,500)\n",
    "\n",
    "# for targe label 1\n",
    "np.random.seed(103)\n",
    "X[500:,0] = np.random.uniform(-1,3,500)\n",
    "np.random.seed(47)\n",
    "X[500:,1] = np.random.uniform(-1,3,500)\n",
    "y = np.array([0 if i < 500 else 1 for i in range(1000)])\n",
    "\n",
    "\n",
    "gda = GDA()\n",
    "gda.fit(X,y)\n",
    "\n",
    "Z0 = [np.exp(-0.5*np.dot(np.dot((x-gda.mu0),np.linalg.pinv(gda.sigma)),(x-gda.mu0))) for x in X]\n",
    "Z1 = [np.exp(-0.5*np.dot(np.dot((x-gda.mu1),np.linalg.pinv(gda.sigma)),(x-gda.mu1))) for x in X]\n",
    "\n",
    "def plot_countour(X,Z0,Z1,y):\n",
    "    # define grid.\n",
    "    xi = np.linspace(-5,5,100)\n",
    "    yi = np.linspace(-5,5,100)\n",
    "\n",
    "    zi0 = griddata((X[:,0], X[:,1]), Z0, (xi[None,:], yi[:,None]), method='cubic')\n",
    "    zi1 = griddata((X[:,0], X[:,1]), Z1, (xi[None,:], yi[:,None]), method='cubic')    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    CS = plt.contour(xi,yi,zi0,10,linewidths=0.5,colors='red')\n",
    "    CS = plt.contour(xi,yi,zi1,10,linewidths=0.5,colors='blue')\n",
    "    \n",
    "    plt.scatter(X[np.where(y==0)[0]][:,0],X[np.where(y==0)[0]][:,1],marker='o',c='red', s=1)\n",
    "    plt.scatter(X[np.where(y==1)[0]][:,0],X[np.where(y==1)[0]][:,1],marker='x',c='blue',s=1)\n",
    "    plt.xlim(-3,3)\n",
    "    plt.ylim(-3,3)\n",
    "    plt.title('gda boundary plot')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print('example where GDA works well')\n",
    "plot_countour(X,np.array(Z0), np.array(Z1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "578a2b5e1a398fcbc7a3a4f49ad19f40",
     "grade": true,
     "grade_id": "import_check_2",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes Classifier\n",
    "\n",
    "#### score 2 (you have to implement everything correctly to get 2 score, no partial scoring, you got either 2 or 0)\n",
    "implement a Multinomial Naive Bayes Classifier for text classification using laplace smoothing\n",
    "\n",
    "X is list of list of tokenized sentence\n",
    "\n",
    "y is the target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0cbd6908772501b19d6aded5cdc544b4",
     "grade": true,
     "grade_id": "import_check_helper_2",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "eed60034254615965d26da0743dde4f4",
     "grade": false,
     "grade_id": "mnb_ans",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class MNB_TextClassifier:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.prior = {}\n",
    "        self.condprob = {}\n",
    "    \n",
    "    # p(class=y | {term0=x[0], term1=x[1], ...} )\n",
    "    def proba_y_given_x(self, y, x):\n",
    "        proaba_y = self.proba_y(y)\n",
    "        for var in x:\n",
    "            if var in self.condprob:\n",
    "                proaba_y *= self.condprob[var][y]\n",
    "            \n",
    "        return proaba_y\n",
    "    \n",
    "    # p(c)\n",
    "    def proba_y(self, y):\n",
    "        return self.prior[y]\n",
    "\n",
    "    # update self.prior[class] as p(class=class) \n",
    "    # update self.condprob[term][class] as p(term=term | class=class)\n",
    "    def fit(self, X, y):\n",
    "        #calculate p(class=class)\n",
    "        y_uniques, y_counts = np.unique(y, return_counts=True)\n",
    "        for i in range (len(y_uniques)):\n",
    "            probability_y = y_counts[i]/float(y.size)\n",
    "            self.prior[y_uniques[i]]=probability_y\n",
    "        \n",
    "        \n",
    "        #calculate p(term|class)\n",
    "        vocabularies =  set(x for l in X for x in l)\n",
    "        class_count = {}\n",
    "        vocab_count = {}\n",
    "        inner_condprob = {}\n",
    "        for val in vocabularies:\n",
    "            self.condprob[val] = {}\n",
    "                \n",
    "        class_count = class_count.fromkeys(self.prior, 0)\n",
    "            \n",
    "        for i in range (len(y_uniques)):\n",
    "            for j in range(len(X)):\n",
    "                if (y_uniques[i] == y[j]):\n",
    "                    class_count[y_uniques[i]] += len(X[j])\n",
    "                    \n",
    "        for i in range (len(y_uniques)):\n",
    "            vocab_count = vocab_count.fromkeys(vocabularies, 0)\n",
    "            for j in range(len(X)):\n",
    "                if(y_uniques[i] == y[j]):\n",
    "                    for k in range (len(X[j])):\n",
    "                        vocab_count[X[j][k]] += 1\n",
    "            for key, value in vocab_count.items():\n",
    "                proaba = (value+1)/(class_count[i]+len(vocabularies))\n",
    "                self.condprob[key][y_uniques[i]] = proaba\n",
    "                \n",
    "                \n",
    "        self.condprob['not_in_vocabularies'] = {}\n",
    "        for i in range (len(y_uniques)):        \n",
    "            self.condprob['not_in_vocabularies'][y_uniques[i]] = 1/(class_count[i]+len(vocabularies))\n",
    "            \n",
    "        print (self.condprob)\n",
    "        return 0\n",
    "        \n",
    "    def predict_single(self, x):\n",
    "        result = dict(self.prior)\n",
    "        for key in self.prior:\n",
    "            result[key] = self.proba_y_given_x(key,x)\n",
    "            \n",
    "        return max(result, key=result.get)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return [self.predict_single(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "05e0465b7049b93df482c2fe2b246488",
     "grade": true,
     "grade_id": "mnb_test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokyo': {0: 0.2222222222222222, 1: 0.07142857142857142}, 'macao': {0: 0.1111111111111111, 1: 0.14285714285714285}, 'japan': {0: 0.2222222222222222, 1: 0.07142857142857142}, 'beijing': {0: 0.1111111111111111, 1: 0.14285714285714285}, 'chinese': {0: 0.2222222222222222, 1: 0.42857142857142855}, 'shanghai': {0: 0.1111111111111111, 1: 0.14285714285714285}, 'not_in_vocabularies': {0: 0.1111111111111111, 1: 0.07142857142857142}}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nArrays are not almost equal to 7 decimals\n ACTUAL: 0.75\n DESIRED: 0.05357142857142857",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-57d9870ae2b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcondprob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'japan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_y_given_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'asdf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.05357142857142857\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproba_y_given_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'chinese'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chinese'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chinese'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tokyo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'japan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.00030121377997263036\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_almost_equal\u001b[0;34m(actual, desired, decimal, err_msg, verbose)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesired\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_build_err_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nArrays are not almost equal to 7 decimals\n ACTUAL: 0.75\n DESIRED: 0.05357142857142857"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "    ['chinese', 'beijing', 'chinese'],\n",
    "    ['chinese', 'chinese', 'shanghai'],\n",
    "    ['chinese', 'macao'],\n",
    "    ['tokyo', 'japan', 'chinese']\n",
    "])\n",
    "\n",
    "#class 1 is china\n",
    "#class 0 is japan\n",
    "y = np.array([1,1,1,0])\n",
    "\n",
    "clf = MNB_TextClassifier()\n",
    "clf.fit(X, y)\n",
    "\n",
    "\n",
    "np.testing.assert_almost_equal(clf.condprob['chinese'][1], 3/7)\n",
    "np.testing.assert_almost_equal(clf.condprob['japan'][1], 1/14)\n",
    "np.testing.assert_almost_equal(clf.condprob['chinese'][0], 2/9)\n",
    "np.testing.assert_almost_equal(clf.condprob['japan'][0], 2/9)\n",
    "\n",
    "np.testing.assert_almost_equal(clf.proba_y_given_x(1, ['asdf']), 0.05357142857142857)\n",
    "\n",
    "np.testing.assert_almost_equal(clf.proba_y_given_x(1, ['chinese', 'chinese', 'chinese', 'tokyo', 'japan']), 0.00030121377997263036)\n",
    "np.testing.assert_almost_equal(clf.proba_y_given_x(1, ['asdfasdfasdf','asdfasdfasdf','chinese', 'chinese', 'chinese', 'tokyo', 'japan']), 1.5368049998603588e-06)\n",
    "\n",
    "np.testing.assert_almost_equal(clf.proba_y_given_x(0, ['chinese', 'chinese', 'chinese', 'tokyo', 'japan']), 0.00013548070246744226)\n",
    "\n",
    "\n",
    "np.testing.assert_almost_equal(clf.proba_y(1), 3/4)\n",
    "np.testing.assert_almost_equal(clf.proba_y(0), 1/4)\n",
    "np.testing.assert_almost_equal(clf.predict_single(['chinese', 'chinese', 'tokyo', 'japan']), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6de7e48f74c582a3e3039826a29ad115",
     "grade": true,
     "grade_id": "import_check_3",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "baf2bbdb60b1df8cd6679eb4c3af1c75",
     "grade": false,
     "grade_id": "cell-f3b7ede3d1085e13",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## OPTIONAL (NO SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# give us your feedback of your experience on taking this test here\n",
    "FEEDBACK = \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
